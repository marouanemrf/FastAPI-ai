{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 25935,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0578368999421631,
      "grad_norm": 0.860806405544281,
      "learning_rate": 4.903797956429536e-05,
      "loss": 0.4907,
      "step": 500
    },
    {
      "epoch": 0.1156737998843262,
      "grad_norm": 0.5946785807609558,
      "learning_rate": 4.807403123192597e-05,
      "loss": 0.4016,
      "step": 1000
    },
    {
      "epoch": 0.1735106998264893,
      "grad_norm": 1.0670000314712524,
      "learning_rate": 4.7110082899556585e-05,
      "loss": 0.3832,
      "step": 1500
    },
    {
      "epoch": 0.2313475997686524,
      "grad_norm": 0.4342011511325836,
      "learning_rate": 4.61461345671872e-05,
      "loss": 0.3771,
      "step": 2000
    },
    {
      "epoch": 0.2891844997108155,
      "grad_norm": 0.6643619537353516,
      "learning_rate": 4.518218623481781e-05,
      "loss": 0.3531,
      "step": 2500
    },
    {
      "epoch": 0.3470213996529786,
      "grad_norm": 0.8222296237945557,
      "learning_rate": 4.421823790244843e-05,
      "loss": 0.3595,
      "step": 3000
    },
    {
      "epoch": 0.4048582995951417,
      "grad_norm": 0.5788008570671082,
      "learning_rate": 4.3254289570079045e-05,
      "loss": 0.3312,
      "step": 3500
    },
    {
      "epoch": 0.4626951995373048,
      "grad_norm": 0.4074738025665283,
      "learning_rate": 4.229034123770966e-05,
      "loss": 0.3428,
      "step": 4000
    },
    {
      "epoch": 0.5205320994794679,
      "grad_norm": 0.5121541619300842,
      "learning_rate": 4.132639290534028e-05,
      "loss": 0.3266,
      "step": 4500
    },
    {
      "epoch": 0.578368999421631,
      "grad_norm": 0.9919013977050781,
      "learning_rate": 4.036244457297089e-05,
      "loss": 0.3248,
      "step": 5000
    },
    {
      "epoch": 0.6362058993637941,
      "grad_norm": 0.5765208601951599,
      "learning_rate": 3.9398496240601506e-05,
      "loss": 0.3213,
      "step": 5500
    },
    {
      "epoch": 0.6940427993059572,
      "grad_norm": 0.987935483455658,
      "learning_rate": 3.843454790823212e-05,
      "loss": 0.3235,
      "step": 6000
    },
    {
      "epoch": 0.7518796992481203,
      "grad_norm": 0.5031874775886536,
      "learning_rate": 3.747059957586274e-05,
      "loss": 0.317,
      "step": 6500
    },
    {
      "epoch": 0.8097165991902834,
      "grad_norm": 0.5844713449478149,
      "learning_rate": 3.650665124349335e-05,
      "loss": 0.3148,
      "step": 7000
    },
    {
      "epoch": 0.8675534991324465,
      "grad_norm": 1.2063151597976685,
      "learning_rate": 3.5542702911123966e-05,
      "loss": 0.3036,
      "step": 7500
    },
    {
      "epoch": 0.9253903990746096,
      "grad_norm": 0.4623134434223175,
      "learning_rate": 3.457875457875458e-05,
      "loss": 0.3021,
      "step": 8000
    },
    {
      "epoch": 0.9832272990167727,
      "grad_norm": 0.4175659120082855,
      "learning_rate": 3.361480624638519e-05,
      "loss": 0.3046,
      "step": 8500
    },
    {
      "epoch": 1.0410641989589358,
      "grad_norm": 0.8630357980728149,
      "learning_rate": 3.265085791401581e-05,
      "loss": 0.2678,
      "step": 9000
    },
    {
      "epoch": 1.098901098901099,
      "grad_norm": 0.9079349637031555,
      "learning_rate": 3.1686909581646426e-05,
      "loss": 0.2716,
      "step": 9500
    },
    {
      "epoch": 1.156737998843262,
      "grad_norm": 1.1366585493087769,
      "learning_rate": 3.0722961249277036e-05,
      "loss": 0.2833,
      "step": 10000
    },
    {
      "epoch": 1.214574898785425,
      "grad_norm": 0.7281486392021179,
      "learning_rate": 2.9759012916907653e-05,
      "loss": 0.2702,
      "step": 10500
    },
    {
      "epoch": 1.2724117987275883,
      "grad_norm": 0.5561742782592773,
      "learning_rate": 2.8795064584538273e-05,
      "loss": 0.264,
      "step": 11000
    },
    {
      "epoch": 1.3302486986697513,
      "grad_norm": 0.9713950753211975,
      "learning_rate": 2.7831116252168887e-05,
      "loss": 0.2621,
      "step": 11500
    },
    {
      "epoch": 1.3880855986119145,
      "grad_norm": 1.8517581224441528,
      "learning_rate": 2.68671679197995e-05,
      "loss": 0.2608,
      "step": 12000
    },
    {
      "epoch": 1.4459224985540775,
      "grad_norm": 0.7262343764305115,
      "learning_rate": 2.5903219587430117e-05,
      "loss": 0.276,
      "step": 12500
    },
    {
      "epoch": 1.5037593984962405,
      "grad_norm": 0.7336316704750061,
      "learning_rate": 2.493927125506073e-05,
      "loss": 0.2623,
      "step": 13000
    },
    {
      "epoch": 1.5615962984384038,
      "grad_norm": 0.5744494795799255,
      "learning_rate": 2.3975322922691347e-05,
      "loss": 0.2633,
      "step": 13500
    },
    {
      "epoch": 1.6194331983805668,
      "grad_norm": 0.6377527713775635,
      "learning_rate": 2.301137459032196e-05,
      "loss": 0.2573,
      "step": 14000
    },
    {
      "epoch": 1.67727009832273,
      "grad_norm": 0.8069213032722473,
      "learning_rate": 2.2047426257952574e-05,
      "loss": 0.2669,
      "step": 14500
    },
    {
      "epoch": 1.735106998264893,
      "grad_norm": 0.596756637096405,
      "learning_rate": 2.108347792558319e-05,
      "loss": 0.2506,
      "step": 15000
    },
    {
      "epoch": 1.792943898207056,
      "grad_norm": 0.7965264320373535,
      "learning_rate": 2.0119529593213804e-05,
      "loss": 0.2487,
      "step": 15500
    },
    {
      "epoch": 1.8507807981492193,
      "grad_norm": 0.4627113342285156,
      "learning_rate": 1.9155581260844418e-05,
      "loss": 0.2534,
      "step": 16000
    },
    {
      "epoch": 1.9086176980913823,
      "grad_norm": 1.170501708984375,
      "learning_rate": 1.8191632928475034e-05,
      "loss": 0.2563,
      "step": 16500
    },
    {
      "epoch": 1.9664545980335455,
      "grad_norm": 0.7770137786865234,
      "learning_rate": 1.722768459610565e-05,
      "loss": 0.2554,
      "step": 17000
    },
    {
      "epoch": 2.0242914979757085,
      "grad_norm": 0.734754204750061,
      "learning_rate": 1.6263736263736265e-05,
      "loss": 0.245,
      "step": 17500
    },
    {
      "epoch": 2.0821283979178715,
      "grad_norm": 1.1442668437957764,
      "learning_rate": 1.529978793136688e-05,
      "loss": 0.2302,
      "step": 18000
    },
    {
      "epoch": 2.1399652978600345,
      "grad_norm": 0.9007337093353271,
      "learning_rate": 1.4335839598997495e-05,
      "loss": 0.224,
      "step": 18500
    },
    {
      "epoch": 2.197802197802198,
      "grad_norm": 0.5558531284332275,
      "learning_rate": 1.3371891266628108e-05,
      "loss": 0.2294,
      "step": 19000
    },
    {
      "epoch": 2.255639097744361,
      "grad_norm": 0.7778898477554321,
      "learning_rate": 1.2407942934258725e-05,
      "loss": 0.2305,
      "step": 19500
    },
    {
      "epoch": 2.313475997686524,
      "grad_norm": 0.6225420832633972,
      "learning_rate": 1.144399460188934e-05,
      "loss": 0.2316,
      "step": 20000
    },
    {
      "epoch": 2.371312897628687,
      "grad_norm": 0.6910607814788818,
      "learning_rate": 1.0480046269519953e-05,
      "loss": 0.2286,
      "step": 20500
    },
    {
      "epoch": 2.42914979757085,
      "grad_norm": 1.0090694427490234,
      "learning_rate": 9.51609793715057e-06,
      "loss": 0.2283,
      "step": 21000
    },
    {
      "epoch": 2.4869866975130135,
      "grad_norm": 0.6476990580558777,
      "learning_rate": 8.552149604781185e-06,
      "loss": 0.2296,
      "step": 21500
    },
    {
      "epoch": 2.5448235974551765,
      "grad_norm": 1.621279239654541,
      "learning_rate": 7.588201272411799e-06,
      "loss": 0.2311,
      "step": 22000
    },
    {
      "epoch": 2.6026604973973395,
      "grad_norm": 1.8837612867355347,
      "learning_rate": 6.624252940042414e-06,
      "loss": 0.2288,
      "step": 22500
    },
    {
      "epoch": 2.6604973973395025,
      "grad_norm": 1.1679866313934326,
      "learning_rate": 5.660304607673029e-06,
      "loss": 0.2257,
      "step": 23000
    },
    {
      "epoch": 2.7183342972816655,
      "grad_norm": 0.7630479335784912,
      "learning_rate": 4.696356275303644e-06,
      "loss": 0.2145,
      "step": 23500
    },
    {
      "epoch": 2.776171197223829,
      "grad_norm": 0.5680502653121948,
      "learning_rate": 3.7324079429342585e-06,
      "loss": 0.2222,
      "step": 24000
    },
    {
      "epoch": 2.834008097165992,
      "grad_norm": 0.5408617258071899,
      "learning_rate": 2.768459610564874e-06,
      "loss": 0.2255,
      "step": 24500
    },
    {
      "epoch": 2.891844997108155,
      "grad_norm": 0.8140094876289368,
      "learning_rate": 1.804511278195489e-06,
      "loss": 0.2221,
      "step": 25000
    },
    {
      "epoch": 2.949681897050318,
      "grad_norm": 0.7190911769866943,
      "learning_rate": 8.405629458261038e-07,
      "loss": 0.2245,
      "step": 25500
    }
  ],
  "logging_steps": 500,
  "max_steps": 25935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6776412880896000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
